{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the difference between connection methodologies and given attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "from typing import List, Tuple\n",
    "from collections.abc import Callable\n",
    "import time\n",
    "import datetime as dt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader, DenseDataLoader\n",
    "\n",
    "from torch_geometric.nn import GraphConv, global_add_pool, DenseGraphConv, dense_diff_pool\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "from torch_geometric.utils import to_dense_adj, to_networkx\n",
    "from torch_geometric.transforms import ToDense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 15, 8.27\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'seaborn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual, FloatSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src/'))\n",
    "\n",
    "from src.utils import load_dataset, ASSETS_DIR, CHECKPOINTS_DIR\n",
    "from src.models import DiffPool, BaselineGNN\n",
    "from src.train import train\n",
    "from src.metrics import evaluate, TrainingMetrics, TestingMetrics\n",
    "\n",
    "CONNECTION_DIR = '/Users/arnauddhaene/Downloads/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the necessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args = dict(num_classes=2, hidden_dim=64, node_features_dim=43)\n",
    "\n",
    "model = BaselineGNN(layer_type='GAT', **model_args)\n",
    "\n",
    "storage_path = os.path.join(ASSETS_DIR + 'models/',\n",
    "                            'Baseline GNN with 5 GAT layers-2021-10-30 13:27:34.879462.pkl')\n",
    "\n",
    "model.load_state_dict(torch.load(storage_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the data used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/arnauddhaene/development/lts4/graphmel/src/../data/checkpoints/wasserstein_20_27_False_2021-11-01.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t8/nv__vwc14ll5v1dl5qwp91gr0000gn/T/ipykernel_24317/2301168528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatafile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINTS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wasserstein_20_27_False_2021-11-01.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/arnauddhaene/development/lts4/graphmel/src/../data/checkpoints/wasserstein_20_27_False_2021-11-01.pt'"
     ]
    }
   ],
   "source": [
    "datafile = open(os.path.join(CHECKPOINTS_DIR, 'wasserstein_20_27_False_2021-11-01.pt'), 'rb')\n",
    "\n",
    "dataset_train, dataset_test = pickle.load(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 45, 1: 26}), Counter({0: 9, 1: 9}))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(list(map(lambda g: g.y.item(), dataset_train))), Counter(list(map(lambda g: g.y.item(), dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_weights(model: torch.nn.Module, graph: Data) -> torch.Tensor:\n",
    "    \n",
    "    x, edge_index = graph.x, graph.edge_index\n",
    "\n",
    "    for step in range(len(model.convs) - 1):\n",
    "        x = model.convs[step](x, edge_index)\n",
    "\n",
    "    x, (edge_index, alpha) = model.convs[-1](x, edge_index, return_attention_weights=True)\n",
    "    \n",
    "    return edge_index, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c127b9f83c4dfa9d68b73aea61021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='example', options=(Data(x=[60, 44], edge_index=[2, 396], y=[1], nuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = dataset_train[41]\n",
    "@interact(example=dataset_train)\n",
    "def show_attention(example: Data):\n",
    "    edge_index, alpha = get_attention_weights(model, example)\n",
    "    \n",
    "    storage = []\n",
    "\n",
    "    for (i, j), a in zip(edge_index.t().tolist(), alpha.flatten().tolist()):\n",
    "        # print(f'{i} -> {j} has weight {a}')\n",
    "\n",
    "        vol = abs(example.x[i, 1] - example.x[j, 1]).item()\n",
    "\n",
    "        storage.append(dict(edge=f'{i} -> {j}', alpha=a, vol_ccm_d=vol))\n",
    "\n",
    "    df = pd.DataFrame(storage)\n",
    "\n",
    "    sns.scatterplot(data=df, x='alpha', y='vol_ccm_d')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "947aba3e9b2ee8e94b9a4f86dd9db3bac2e8c16055cb5eb2c317ce168f84ce4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ds': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
