{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79589284-9fd2-481a-b49c-1fbc64723147",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d5e16-6939-4079-b14a-3ba59d0c966c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Torch import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e663f0-4fdf-4f81-bc05-74ebbdafae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cpu.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cpu.html\n",
    "# !pip install -q torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d9e57-89c7-4271-97c2-02ddff910794",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67a0916-2989-4479-b091-c2263447e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from typing import List, Tuple\n",
    "from collections.abc import Callable\n",
    "import time\n",
    "import datetime as dt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd71b21-e509-4781-863c-afe3b98a5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b4572d-a189-4915-bb5d-930d5593c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d989082f-b8e4-4625-84e3-91f698c641a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1503fd5d-0c95-4112-95ba-df1549c750da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader, DenseDataLoader\n",
    "\n",
    "from torch_geometric.nn import GraphConv, global_add_pool, DenseGraphConv, dense_diff_pool\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.transforms import ToDense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f57fad-f38b-4fe2-988b-1770f196486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 15, 8.27\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'seaborn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7a647c-a585-4eaa-a74f-5ebb94eedc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual, FloatSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "837c40be-b6e2-4a26-948e-4eb0268cc031",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src/'))\n",
    "\n",
    "from src.utils import load_dataset\n",
    "from src.models import DiffPool\n",
    "from src.train import train\n",
    "from src.metrics import evaluate_accuracy\n",
    "\n",
    "CONNECTION_DIR = '/Users/arnauddhaene/Downloads/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6723981b-4554-4dd7-8431-23a95ab89ec6",
   "metadata": {},
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d978936e-e9b0-4403-881d-677ad12948f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = dict(\n",
    "    num_classes=2,\n",
    "    hidden_dim=64,\n",
    "    node_features_dim=37)\n",
    "\n",
    "model = DiffPool(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "242d4b47-df74-45e4-92ff-bd8bf45a3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train, loader_val, loader_test = load_dataset(dense=model.is_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13e83fb-969a-468a-88c1-ae3da69d9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NLLLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "device = None\n",
    "dense = model.is_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86967471-5bd3-4d47-bdb9-2fe55c8a6062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2c8748282c45de97dd093cf6309a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train: 0.565, Val: 0.667, Loss: 2124028159501770714983388151808.000\n",
      "Epoch: 015, Train: 0.710, Val: 0.667, Loss: 16881912181719479160271798272.000\n",
      "Epoch: 030, Train: 0.645, Val: 0.667, Loss: 2327043187183750518385777049600.000\n",
      "Epoch: 045, Train: 0.645, Val: 0.667, Loss: 279402845786192290017565474816.000\n",
      "Epoch: 060, Train: 0.629, Val: 0.556, Loss: 444568559791906330686378737664.000\n",
      "Epoch: 075, Train: 0.661, Val: 0.333, Loss: 679860087834391.750\n",
      "Epoch: 090, Train: 0.629, Val: 0.444, Loss: 337727548204084906780837019648.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(100)):\n",
    "    epoch_loss = 0.\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in loader_train:\n",
    "        batch.to(device)\n",
    "\n",
    "        if dense:\n",
    "            output, _, _ = model(batch.x, batch.adj, batch.mask)\n",
    "        else:\n",
    "            output = model(batch.x, batch.edge_index, batch.batch)\n",
    "\n",
    "        loss = criterion(output, batch.y.flatten())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        epoch_loss += batch.y.size(0) * loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    acc_train = evaluate_accuracy(model, loader_train, dense=dense)\n",
    "    acc_valid = evaluate_accuracy(model, loader_val, dense=dense)\n",
    "    \n",
    "    if epoch % 15 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train: {acc_train:.3f}, Val: {acc_valid:.3f}, Loss: {epoch_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0506a93-9dc4-43b4-a0a5-46399d876f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(model, loader_test, dense=model.is_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86bb02-027d-4c15-adf3-203f404d5d05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Modified methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4c08bed-0e38-45d0-87e8-e1178a54d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    connectivity: str = 'wasserstein', batch_size: int = 8,\n",
    "    test_size: float = 0.2, val_size: float = 0.1, seed: int = 27,\n",
    "    verbose: int = 0\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Get training, validation, and testing DataLoaders.\n",
    "    Mainly used as a high-level data fetcher in the running script.\n",
    "\n",
    "    Args:\n",
    "        connectivity (str, optional): node connectivity method.. Defaults to 'wasserstein'.\n",
    "        batch_size (int, optional): [description]. Defaults to 8.\n",
    "        test_size (float, optional): Ratio of test set. Defaults to 0.2.\n",
    "        val_size (float, optional): Ratio of validation set. Defaults to 0.1.\n",
    "        seed (int, optional): Random seed. Defaults to 27.\n",
    "        verbose (int, optional): tuneable parameter for output verbosity. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "            * loader_train (DataLoader): packaged training dataset.\n",
    "            * loader_val (DataLoader): packaged validation dataset.\n",
    "            * loader_test (DataLoader): packaged testing dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    labels, lesions, patients = fetch_data(verbose)\n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "        preprocess(labels, lesions, patients,\n",
    "                   test_size=test_size, val_size=val_size, seed=seed,\n",
    "                   verbose=verbose)\n",
    "        \n",
    "    loader_train = create_dataset(X=X_train, Y=y_train,\n",
    "                                  batch_size=batch_size,\n",
    "                                  connectivity=connectivity, verbose=verbose)\n",
    "    loader_val = create_dataset(X=X_val, Y=y_val,\n",
    "                                batch_size=batch_size,\n",
    "                                connectivity=connectivity, verbose=verbose)\n",
    "    \n",
    "    # In the test loader we set the batch size to be\n",
    "    # equal to the size of the whole test set\n",
    "    loader_test = create_dataset(X=X_test, Y=y_test,\n",
    "                                 batch_size=len(y_test), shuffle=False,\n",
    "                                 connectivity=connectivity, verbose=verbose)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print('Final amount of datapoints \\n' \\\n",
    "              + f'  Train: {len(loader_train.dataset)} \\n' \\\n",
    "              + f'  Validation: {len(loader_val.dataset)} \\n' \\\n",
    "              + f'  Test: {len(loader_test.dataset)}')\n",
    "\n",
    "    return loader_train, loader_val, loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa18e81-592a-43d1-b636-0b4c4267f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    X: pd.DataFrame, Y: pd.Series, batch_size: int = 8, shuffle: bool = True,\n",
    "    connectivity: str = 'wasserstein', distance: float = 0.5, verbose: int = 0\n",
    ") -> DataLoader:\n",
    "    \"\"\"Packages preprocessed data and its labels into a `torch.utils.data.DataLoader`\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): `gpcr_id` indexed datapoints (lesions)\n",
    "        Y (pd.Series): `gpcr_id` indexed labels. 1 is NPD.\n",
    "        batch_size (int, optional): DataLoader batch size. Defaults to 8.\n",
    "        shuffle (bool, optional): shuffle graphs in DataLoader. Defaults to True.\n",
    "        connectivity (str, optional): node connectivity method. Defaults to 'wasserstein'.\n",
    "        distance (float, optional): if `wasserstein` connectivity is chosen,\n",
    "            the threshold distance in order to create an edge between nodes. Defaults to 0.5.\n",
    "        verbose (int, optional): tuneable parameter for output verbosity.. Defaults to 0.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: acceptable values for connectivity are: 'fully', 'organ', and 'wasserstein'\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: packaged dataset within a DataLoader instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    lesions = pd.read_csv(os.path.join(CONNECTION_DIR + DATA_FOLDERS[2], FILES[DATA_FOLDERS[2]]['lesions']))\n",
    "    # Filter out benign lesions and non-post-1 studies\n",
    "    lesions = lesions[(lesions.pars_classification_petct != 'benign') & (lesions.study_name == 'post-01')]\n",
    "    \n",
    "    max_num_nodes = lesions.groupby('gpcr_id').size().max()\n",
    "    \n",
    "    dataset = []\n",
    "    skipped = 0\n",
    "    \n",
    "    to_dense = ToDense(num_nodes=max_num_nodes)\n",
    "\n",
    "    for patient in list(X.index.unique()):\n",
    "\n",
    "        # Create patient sub-DataFrame of all his post-1 study lesions\n",
    "        pdf = lesions[lesions.gpcr_id == patient].reset_index()\n",
    "        \n",
    "        # Sanity check\n",
    "        assert pdf.shape[0] == X[X.index == patient].shape[0], f'Unequal lesion count for patient {patient}'\n",
    "        \n",
    "        num_nodes = pdf.shape[0]\n",
    "        edge_index = []\n",
    "        \n",
    "        # Skip single-noded graphs\n",
    "        if num_nodes < 2:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Connect lesions using different methodologies\n",
    "        if connectivity == 'organ':\n",
    "            # Connect all lesions that are assigned to the same organ\n",
    "            for i in range(num_nodes):\n",
    "                source = pdf.loc[i].assigned_organ\n",
    "                targets = list(pdf[pdf.assigned_organ == source].index)\n",
    "\n",
    "                edge_index.extend([[i, j] for j in targets if i != j])\n",
    "                \n",
    "        elif connectivity == 'fully':\n",
    "            # Create a fully-connected network representation\n",
    "            edge_index = list(permutations(range(num_nodes), 2, ))\n",
    "            \n",
    "        elif connectivity == 'wasserstein':\n",
    "            # Use the mean and std of the SUV of each lesion to simulate SUV distributions (normal)\n",
    "            # and subsequently connect nodes with similar SUV distributions using the Wasserstein distance\n",
    "            # as a distance metric\n",
    "            for i in range(num_nodes):\n",
    "                source_mean, source_sd = pdf.loc[i].mean_suv_val, pdf.loc[i].sd_suv_val\n",
    "                source_distribution = np.random.normal(source_mean, source_sd, 1000)\n",
    "                \n",
    "                targets = [id for id, mu, sd in zip(pdf.index, pdf.mean_suv_val, pdf.sd_suv_val)\n",
    "                           if wasserstein_distance(source_distribution,\n",
    "                                                   np.random.normal(mu, sd, 1000)) < distance]\n",
    "\n",
    "                edge_index.extend([[i, j] for j in targets])\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f'Connectivity value not accepted: {connectivity}.'\n",
    "                             \"Must be either 'fully', 'wasserstein', or 'organ'.\")\n",
    "\n",
    "        edge_index = torch.tensor(edge_index).t().long()\n",
    "    \n",
    "        x = torch.tensor(X.loc[patient].reset_index(drop=True).to_numpy().astype(np.float32))\n",
    "        y = torch.tensor(Y.loc[patient])\n",
    "\n",
    "        dataset.append(to_dense(\n",
    "            Data(x=x, edge_index=edge_index, num_nodes=num_nodes, y=y.reshape(-1))))\n",
    "        \n",
    "    if verbose > 0:\n",
    "        print(f'Skipped {skipped} graphs as they have less than 2 nodes.')\n",
    "        \n",
    "    return DenseDataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa0035-a8b1-4c56-bdbb-2b57cb3ec5b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Testing the difference between GraphConv and DenseGraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23799ae4-6831-4932-a2d9-7eb599382ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = loader_train.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94933b40-8733-401c-b3b1-620624ffe57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53e20dd9-6148-4e09-8503-44a21dc98f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 37\n",
    "sparse_conv = GraphConv(channels, channels)\n",
    "dense_conv = DenseGraphConv(channels, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e025048-5a3e-428f-afd5-c8e55e13ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that initial weights are the same\n",
    "for p1, p2 in zip(dense_conv.parameters(), sparse_conv.parameters()):\n",
    "    p1 = p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "327feb18-9317-4a21-a597-0dbf3e54a8a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`MessagePassing.propagate` only supports `torch.LongTensor` of shape `[2, num_messages]` or `torch_sparse.SparseTensor` for argument `edge_index`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t8/nv__vwc14ll5v1dl5qwp91gr0000gn/T/ipykernel_43314/794969376.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msparse_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0msparse_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torch_geometric/nn/conv/graph_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n\u001b[0m\u001b[1;32m     70\u001b[0m                              size=size)\n\u001b[1;32m     71\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__check_input__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Run \"fused\" message and aggregation (if applicable).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m__check_input__\u001b[0;34m(self, edge_index, size)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mthe_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    125\u001b[0m             ('`MessagePassing.propagate` only supports `torch.LongTensor` of '\n\u001b[1;32m    126\u001b[0m              \u001b[0;34m'shape `[2, num_messages]` or `torch_sparse.SparseTensor` for '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `MessagePassing.propagate` only supports `torch.LongTensor` of shape `[2, num_messages]` or `torch_sparse.SparseTensor` for argument `edge_index`."
     ]
    }
   ],
   "source": [
    "sparse_out = sparse_conv(example.x, example.edge_index)\n",
    "assert sparse_out.size() == (example.num_nodes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051bb59-1f09-4d18-b3ba-82de369b1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToDense()(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779cedf-cacc-47c8-b511-0eba03b0eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e791a-818c-4ad6-8f97-20ae91cfc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_out = dense_conv(example.x, example.adj, example.mask)[0]\n",
    "\n",
    "assert dense_out.size() == (example.num_nodes, channels)\n",
    "\n",
    "assert torch.allclose(sparse_out, dense_out, atol=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557d890-8de2-47ad-81cf-eecab424a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(sparse_out.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75255090-c3e8-4fa9-b364-6b398b5a91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dense_out.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4720da0-1f00-4709-bfe1-196dc00f7720",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing DiffPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e275ef2-2a2a-4d81-a450-9328b7ea6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        num_classes: int,\n",
    "        hidden_dim: int,\n",
    "        node_features_dim: int,\n",
    "    ):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        num_nodes_1 = 50\n",
    "        \n",
    "        self.gnn1_pool = GNN(node_features_dim, hidden_dim, num_nodes_1)\n",
    "        self.gnn1_embed = GNN(node_features_dim, hidden_dim, hidden_dim)\n",
    "        \n",
    "        num_nodes_2 = 5\n",
    "        \n",
    "        self.gnn2_pool = GNN(hidden_dim, hidden_dim, num_nodes_2)\n",
    "        self.gnn2_embed = GNN(hidden_dim, hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.gnn3_embed = GNN(hidden_dim, hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin2 = torch.nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        \n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x, adj, s, mask)\n",
    "        \n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "\n",
    "        x, adj, l2, e2 = dense_diff_pool(x, adj, s)\n",
    "        \n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        \n",
    "        x = x.mean(dim=1)\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe4b36-be85-4192-baeb-7c991dc5f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffPool(num_classes=2, hidden_dim=32, node_features_dim=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f6a62-1efb-479a-b235-fb8b7fee47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for data in loader:\n",
    "        pred = model(data.x, data.adj, data.mask)[0].max(dim=1)[1]\n",
    "        correct += pred.eq(data.y.view(-1)).sum().item()\n",
    "        \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3735c1-c053-4276-beb0-5222f0d0c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=0.001)\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_a = 0.\n",
    "\n",
    "    for batch in loader_train:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _, _ = model(batch.x, batch.adj, batch.mask)\n",
    "        \n",
    "        loss = F.nll_loss(output, batch.y.view(-1))\n",
    "        loss.backward()\n",
    "        loss_a += batch.y.size(0) * loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 15 == 0:\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Train loss: {loss_a / len(loader_train.dataset):.4f}')\n",
    "\n",
    "        tra_acc = test(loader_train)\n",
    "        val_acc = test(loader_val)\n",
    "\n",
    "        print(f'Training acc: {tra_acc:.4f}, Validation acc: {val_acc:.4f}')\n",
    "                       \n",
    "tes_acc = test(loader_test)\n",
    "print(f'Testing acc: {tes_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "947aba3e9b2ee8e94b9a4f86dd9db3bac2e8c16055cb5eb2c317ce168f84ce4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ds': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
