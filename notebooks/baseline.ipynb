{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-1800e7bd-c754-4151-9d53-0acde7035dd8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Baseline model for progression prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "cell_id": "00003-985b5122-dda6-4102-9e6e-e7e678f7053d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6215,
    "execution_start": 1633527040792,
    "source_hash": "6212ef44"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = 'seaborn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00005-54c98b3e-0f68-4cef-8053-756836fa5466",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 694,
    "execution_start": 1633527057803,
    "source_hash": "20fe91fc"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import fetch_data\n",
    "\n",
    "labels, lesions, patients = fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesions_agg = lesions.groupby('gpcr_id').agg({\n",
    "    'vol_ccm': np.sum,\n",
    "    'max_suv_val': np.mean,\n",
    "    'mean_suv_val': np.mean,\n",
    "    'min_suv_val': np.mean,\n",
    "    'sd_suv_val': np.mean,\n",
    "    'assigned_organ': pd.Series.tolist\n",
    "}).reset_index()\n",
    "\n",
    "dataset = lesions_agg.merge(patients, on='gpcr_id', how='inner')\n",
    "dataset.set_index('gpcr_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Preprocessor\n",
    "\n",
    "# Separate features by type\n",
    "numerical = list(dataset.select_dtypes(np.number).columns)\n",
    "categorical = list(dataset.select_dtypes([bool, object]).columns)\n",
    "multivalue = ['assigned_organ', 'immuno_therapy_type']\n",
    "\n",
    "# Remove multivalue features from categorical ones\n",
    "for feature in multivalue:\n",
    "    categorical.remove(feature)\n",
    "    \n",
    "features_range = list(range(len(numerical) + len(categorical) + len(multivalue)))\n",
    "bp = np.cumsum([len(numerical), len(categorical), len(multivalue)])\n",
    "\n",
    "# Build PipeLine of ColumnTransformers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "ct = Pipeline([\n",
    "    ('imputers', ColumnTransformer([\n",
    "        ('median', SimpleImputer(strategy='median'), numerical),\n",
    "        ('frequent', SimpleImputer(strategy='most_frequent'), categorical)\n",
    "    ], remainder='passthrough')),\n",
    "    ('preprocess', ColumnTransformer([\n",
    "        ('scaler', StandardScaler(), features_range[0:bp[0]]),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'), features_range[bp[0]:bp[1]]),\n",
    "        ('count-vec1', CountVectorizer(analyzer=set), features_range[bp[1]:bp[2]][0]),\n",
    "        ('count-vec2', CountVectorizer(analyzer=set), features_range[bp[1]:bp[2]][1])\n",
    "    ], remainder='passthrough')),\n",
    "])\n",
    "\n",
    "ppor = Preprocessor(\n",
    "    pipe=ct,\n",
    "    feats_out_fn=lambda ct: ct.named_steps['imputers'].transformers_[0][2] \\\n",
    "        + list(ct.named_steps['preprocess'].transformers_[1][1].get_feature_names()) \\\n",
    "        + ct.named_steps['preprocess'].transformers_[2][1].get_feature_names() \\\n",
    "        + ct.named_steps['preprocess'].transformers_[3][1].get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "I_train, I_test, y_train, y_test = \\\n",
    "    train_test_split(labels.index, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "ppor.fit(dataset.loc[I_train])\n",
    "\n",
    "X_train = ppor.transform(dataset.loc[I_train]) \n",
    "X_test = ppor.transform(dataset.loc[I_test]) \n",
    "\n",
    "y_train = labels.loc[I_train]\n",
    "y_test = labels.loc[I_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=7),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=.01, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(penalty='l2', solver='liblinear')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aba20c210c3401387b69c733083276e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for name, clf in tqdm(zip(names, classifiers), total=len(names)):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors    0.6111\n",
      "Linear SVM           0.6667\n",
      "RBF SVM              0.7778\n",
      "Gaussian Process     0.6111\n",
      "Decision Tree        0.7778\n",
      "Random Forest        0.5556\n",
      "Neural Net           0.5000\n",
      "AdaBoost             0.6111\n",
      "Naive Bayes          0.2222\n",
      "Logistic Regression  0.7222\n"
     ]
    }
   ],
   "source": [
    "for method, score in list(zip(names, scores)):\n",
    "    print(f'{method:<20} {score:,.4f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "947aba3e9b2ee8e94b9a4f86dd9db3bac2e8c16055cb5eb2c317ce168f84ce4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ds': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
